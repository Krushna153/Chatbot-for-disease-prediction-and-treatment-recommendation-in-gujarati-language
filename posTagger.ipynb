{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn_crfsuite in c:\\users\\krushna\\anaconda3\\lib\\site-packages (0.3.6)\n",
      "Requirement already satisfied: six in c:\\users\\krushna\\appdata\\roaming\\python\\python37\\site-packages (from sklearn_crfsuite) (1.14.0)\n",
      "Requirement already satisfied: tqdm>=2.0 in c:\\users\\krushna\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (4.36.1)\n",
      "Requirement already satisfied: tabulate in c:\\users\\krushna\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (0.8.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.8.3 in c:\\users\\krushna\\anaconda3\\lib\\site-packages (from sklearn_crfsuite) (0.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn_crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sklearn_crfsuite\n",
    "import sklearn\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "\n",
    "class posTagger():\n",
    "\n",
    "    def __init__(self, model='guj'):\n",
    "        if not model.endswith('.rtm'):\n",
    "            self.model_ = model+'.rtm'\n",
    "        else:\n",
    "            self.model_ = model\n",
    "\n",
    "    def add_feature(self, features, feature_list, feature_name = None, func = None, **kwargs):\n",
    "        if feature_name == None:\n",
    "            raise ValueError(\"Argument 'feature_name' cannot be NoneType\")\n",
    "        if type(feature_name)!=\"<class 'str'>\":\n",
    "            raise TypeError(\"Argument 'feature_name' cannot be a \"+ str(type(feature_name)))\n",
    "        try:\n",
    "            features[feature_name] = func(sentence, **kwargs)\n",
    "            feature_list.append[feature_name]\n",
    "            num_features = len(feature_list)\n",
    "            return (num_features, features, feature_list)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            return False\n",
    "\n",
    "    def delete_feature(self, features, feature_list, feature_name=None):\n",
    "        if feature_name == None:\n",
    "            raise ValueError(\"Argument 'feature_name' cannot be NoneType\")\n",
    "        if type(feature_name)!=\"<class 'str'>\":\n",
    "            raise TypeError(\"Argument 'feature_name' cannot be a \"+ str(type(feature_name)))\n",
    "        try:\n",
    "            del(features[feature_name])\n",
    "            del(feature_list[feature_list.index(feature_name)])\n",
    "            num_features = len(feature_list)\n",
    "            return (num_features, features, feature_list)\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            return False\n",
    "\n",
    "    def word2feature(self, sent, i):\n",
    "        sent = sent.strip(' ').split(\" \")\n",
    "        word_n_tags = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                word_n_tags.append([word.split('\\\\')[0], word.split('\\\\')[1]])\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            word = word_n_tags[i][0]\n",
    "            postag = word_n_tags[i][1]\n",
    "            features = {\n",
    "            'bias': 1.0,\n",
    "            'word[-4:]': word[-4:],\n",
    "            'word[-3:]': word[-3:],\n",
    "            'word[:3]':word[:3],\n",
    "            'word[:4]':word[:4],\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "            }\n",
    "\n",
    "            if i > 0:\n",
    "                word1 = word_n_tags[i-1][0]\n",
    "                postag1 = word_n_tags[i-1][1]\n",
    "                features.update({\n",
    "                '-1:word.isdigit()': word1.isdigit(),\n",
    "                '-1:word[-3:]':word1[-3:],\n",
    "                '-1:word[-4:]':word1[-4:],\n",
    "                '-1:word[:3]':word1[:3],\n",
    "                '-1:word[:4]':word1[:4],\n",
    "                '-1:postag': postag1,\n",
    "                '-1:postag[-3:]': postag1[-3:]\n",
    "                })\n",
    "            else:\n",
    "                features['BOS'] = True\n",
    "\n",
    "            if i < len(word_n_tags)-1:\n",
    "                word1 = word_n_tags[i+1][0]\n",
    "                postag1 = word_n_tags[i+1][1]\n",
    "                features.update({\n",
    "                '+1:word.isdigit()':word1.isdigit(),\n",
    "                '+1:word[-3:]':word1[-3:],\n",
    "                '+1:word[-4:]':word1[-4:],\n",
    "                '+1:word[:3]':word1[:3],\n",
    "                '+1:word[:4]':word1[:4],\n",
    "                '+1:postag': postag1,\n",
    "                '+1:postag[-3:]': postag1[-3:],\n",
    "                })\n",
    "            else:\n",
    "                features['EOS'] = True\n",
    "\n",
    "        except:\n",
    "            features=None\n",
    "\n",
    "        return features\n",
    "\n",
    "    def sent2features(self, sent):\n",
    "        sentence = sent.strip(' ').split()\n",
    "        sent_to_features = []\n",
    "        for i in range(len(sentence)):\n",
    "            a = self.word2feature(sent,i)\n",
    "            if a!=None:\n",
    "                sent_to_features.append(a)\n",
    "        return sent_to_features\n",
    "\n",
    "    def sent2tokens(self, sent):\n",
    "        sent = sent.strip(' ').split(' ')\n",
    "        sent_to_tokens = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                sent_to_tokens.append(word.split('\\\\')[0])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        return sent_to_tokens\n",
    "\n",
    "\n",
    "    def sent2tags(self, sent):\n",
    "        sent = sent.strip(' ').split(' ')\n",
    "        return_list = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                return_list.append(word.split('\\\\')[1])\n",
    "            except IndexError:\n",
    "                pass\n",
    "        return return_list\n",
    "\n",
    "\n",
    "    def read_text_from_corpus(self, path_to_corpus):\n",
    "        data = pd.read_csv(path_to_corpus)\n",
    "        list_sents = data[\"Value\"].tolist()\n",
    "        return list_sents\n",
    "\n",
    "    def data_from_corpus(self, path_to_corpus):\n",
    "        list_sents = self.read_text_from_corpus(path_to_corpus)\n",
    "        train_X = [self.sent2features(sentence) for sentence in list_sents]\n",
    "        train_y = [self.sent2tags(sentence) for sentence in list_sents]\n",
    "        return (train_X, train_y)\n",
    "\n",
    "    def train(self, train_X, train_y, algorithm='lbfgs', c1=0.6, c2=0.01, max_iterations=100, optimize_hyperparameters=False, all_possible_transitions=True, save=False):\n",
    "        if save==True and self.model_=='guj.rtm':\n",
    "            raise ValueError(\"Model name must be given as an argument to the posTagger() constructor.\")\n",
    "        if optimize_hyperparameters:\n",
    "            print(\"Optimizing hyperparameters........\")\n",
    "            rs = self.optimize_hyperparameters(train_X, train_y)\n",
    "            crf = rs.best_estimator_\n",
    "        else:\n",
    "            crf = sklearn_crfsuite.CRF(\n",
    "                algorithm=algorithm,\n",
    "                c1=c1,\n",
    "                c2=c2,\n",
    "                max_iterations=max_iterations,\n",
    "                all_possible_transitions=all_possible_transitions\n",
    "                )\n",
    "        print(\"Training the model............\")\n",
    "        crf.fit(train_X, train_y)\n",
    "        print(\"Done\")\n",
    "\n",
    "        if save:\n",
    "            with open(self.model_, \"wb\") as f:\n",
    "                pickle.dump(crf,f)\n",
    "\n",
    "    def evaluate(self, test_X, test_y, metric='flat_f1_score', average='weighted', digits=3):\n",
    "        if self.model_==None:\n",
    "            raise ValueError(\"Model can not be NoneType. Load an existing model or create a new one and pass as a parameter\")\n",
    "        with open(self.model_, 'rb') as f:\n",
    "            crf = pickle.load(f)\n",
    "        labels = list(crf.classes_)\n",
    "        pred_y = crf.predict(test_X)\n",
    "        if metric == 'flat_f1_score':\n",
    "            flat_f1_score = metrics.flat_f1_score(test_y, pred_y, average=average, labels=labels)\n",
    "            print(flat_f1_score)\n",
    "\n",
    "        if metric=='flat_classification_report':\n",
    "            sorted_labels = sorted(labels)\n",
    "            print(metrics.flat_classification_report(\n",
    "                test_y, pred_y, labels=sorted_labels, digits=digits\n",
    "                ))\n",
    "\n",
    "    def load(self):\n",
    "        try:\n",
    "            with open(self.model_, 'rb') as f:\n",
    "                crf = pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError('Specified model could not be found. Please make sure it is within the working directory or you have mentioned the path to the file.')\n",
    "\n",
    "        return crf\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        if self.model_==None:\n",
    "            raise ValueError('Model can not be NoneType. Load an existing model or train a new one and pass it as a parameter')\n",
    "        with open(self.model_,\"rb\") as f:\n",
    "            crf = pickle.load(f)\n",
    "        pred_y = crf.predict(test_X)\n",
    "        return pred_y\n",
    "\n",
    "    def optimize_hyperparameters(self, train_X, train_y, metric='flat_f1_score', average='weighted', cv=5, verbose=2, n_jobs=-1, n_iter=10):\n",
    "        params_space = {\n",
    "        'c1': scipy.stats.expon(scale=0.5),\n",
    "        'c2': scipy.stats.expon(scale=0.05)\n",
    "        }\n",
    "\n",
    "        with open(self.model_,'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "        labels = list(model.classes_)\n",
    "\n",
    "        if metric=='flat_f1_score':\n",
    "            scorer = make_scorer(metrics.flat_f1_score, average=average, labels=labels)\n",
    "            rs = RandomizedSearchCV(model, params_space,\n",
    "                        cv=cv,\n",
    "                        verbose=verbose,\n",
    "                        n_jobs=n_jobs,\n",
    "                        n_iter=n_iter,\n",
    "                        scoring=scorer)\n",
    "            rs.fit(train_X, train_y)\n",
    "            return rs\n",
    "        else:\n",
    "            print(\"Optimization currently unavailable for the given metric\")\n",
    "            return None\n",
    "\n",
    "    def sentence_to_features(self, sentence):\n",
    "        punctuations = ['.',',','\"',\"'\",\"!\",'?','<','>','/','&',\"%\",\"#\",'@','-','+','*','(',\")\"]\n",
    "        sent = sentence.strip(' ').split()\n",
    "        sentence_features = []\n",
    "        for word,i in zip(sent, range(len(sent))):\n",
    "            features = {\n",
    "            'bias': 1.0,\n",
    "            'word[-4:]': word[-4:],\n",
    "            'word[-3:]': word[-3:],\n",
    "            'word[:3]':word[:3],\n",
    "            'word[:4]':word[:4],\n",
    "            'word.isdigit()': word.isdigit(),\n",
    "            }\n",
    "            if i > 0:\n",
    "                word1 = sent[i-1]\n",
    "                features.update({\n",
    "                '-1:word.isdigit()': word1.isdigit(),\n",
    "                '-1:word[-3:]':word1[-3:],\n",
    "                '-1:word[-4:]':word1[-4:],\n",
    "                '-1:word[:3]':word1[:3],\n",
    "                '-1:word[:4]':word1[:4]})\n",
    "                if word1 in punctuations:\n",
    "                    features.update({\n",
    "                    '-1:postag': 'RD_PUNC',\n",
    "                    '-1:postag[-3:]': 'UNC'})\n",
    "            else:\n",
    "                features['BOS'] = True\n",
    "            if i < len(sent)-1:\n",
    "                word1 = sent[i+1]\n",
    "                features.update({\n",
    "                '+1:word.isdigit()': word1.isdigit(),\n",
    "                '+1:word[-3:]':word1[-3:],\n",
    "                '+1:word[-4:]':word1[-4:],\n",
    "                '+1:word[:3]':word1[:3],\n",
    "                '+1:word[:4]':word1[:4],})\n",
    "                if word1 in punctuations:\n",
    "                    features.update({\n",
    "                    '+1:postag': 'RD_PUNC',\n",
    "                    '+1:postag[-3:]': 'UNC'})\n",
    "            else:\n",
    "                features['EOS'] = True\n",
    "            sentence_features.append(features)\n",
    "        return sentence_features\n",
    "\n",
    "\n",
    "    def pos_tag(self, sent):\n",
    "        sent = re.sub(r'([.,\\'\\\\\"!?%#@*<>\\+\\-\\(\\)])', r' \\1', sent)\n",
    "        sent = re.sub(r'\\u200b', r'', sent)\n",
    "        sent = re.sub(r'\\ufeff', r'', sent)\n",
    "        sent = re.sub(r'\\n', r' ', sent)\n",
    "        sentence = sent\n",
    "        sent = self.sentence_to_features(sent)\n",
    "        y = self.predict([sent])\n",
    "        return_list = []\n",
    "        for word, tag in zip(sentence.split(), y[0]):\n",
    "            return_list.append((word, tag))\n",
    "        return return_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
